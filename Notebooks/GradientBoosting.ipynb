{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ec62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bd50a",
   "metadata": {},
   "source": [
    "# Gradient boosting\n",
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3cca90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "path_df = \"Pickles/df.pickle\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)\n",
    "\n",
    "# features_train\n",
    "path_features_train = \"Pickles/features_train.pickle\"\n",
    "with open(path_features_train, 'rb') as data:\n",
    "    features_train = pickle.load(data)\n",
    "\n",
    "# labels_train\n",
    "path_labels_train = \"Pickles/labels_train.pickle\"\n",
    "with open(path_labels_train, 'rb') as data:\n",
    "    labels_train = pickle.load(data)\n",
    "\n",
    "# features_test\n",
    "path_features_test = \"Pickles/features_test.pickle\"\n",
    "with open(path_features_test, 'rb') as data:\n",
    "    features_test = pickle.load(data)\n",
    "\n",
    "# labels_test\n",
    "path_labels_test = \"Pickles/labels_test.pickle\"\n",
    "with open(path_labels_test, 'rb') as data:\n",
    "    labels_test = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afb24f",
   "metadata": {},
   "source": [
    "### Cross-Validation for Hyperparameter tuning\n",
    "\n",
    "Hyperparameters of the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85abcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'ccp_alpha': 0.0,\n",
      " 'criterion': 'friedman_mse',\n",
      " 'init': None,\n",
      " 'learning_rate': 0.1,\n",
      " 'loss': 'deviance',\n",
      " 'max_depth': 3,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_iter_no_change': None,\n",
      " 'random_state': None,\n",
      " 'subsample': 1.0,\n",
      " 'tol': 0.0001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "print(gbc.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e83e6",
   "metadata": {},
   "source": [
    "#### Gradient boosting takes a lot of time, investigate only max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d134f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END ........................................max_depth=3; total time= 3.7min\n",
      "[CV] END ........................................max_depth=3; total time= 3.7min\n",
      "[CV] END ........................................max_depth=3; total time= 3.6min\n",
      "[CV] END ........................................max_depth=4; total time= 4.8min\n",
      "[CV] END ........................................max_depth=4; total time= 4.8min\n",
      "[CV] END ........................................max_depth=4; total time= 4.7min\n",
      "[CV] END ........................................max_depth=5; total time= 5.4min\n",
      "[CV] END ........................................max_depth=5; total time= 5.5min\n",
      "[CV] END ........................................max_depth=5; total time= 5.4min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'max_depth': [3, 4, 5]}, scoring='accuracy',\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = [3,4,5]\n",
    "\n",
    "param_grid = {'max_depth': max_depth}\n",
    "\n",
    "# Definition of the search\n",
    "grid_search = GridSearchCV(estimator = gbc,\n",
    "                           param_grid = param_grid,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 3,\n",
    "                           verbose = 2)\n",
    "\n",
    "# Fit the random search model\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e079f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'max_depth': 3}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.8070551549405574\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d37122",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266942a",
   "metadata": {},
   "source": [
    "### Model fit and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc986c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "best_gbc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45345b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "gbc_pred = best_gbc.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63e6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.8957967907490417\n",
      "The test accuracy is: \n",
      "0.8076448828606658\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, best_gbc.predict(features_train)))\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, gbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7771bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.89      0.87      0.88        54\n",
      "         C++       0.97      0.89      0.93        44\n",
      "     Fortran       0.92      0.95      0.93        37\n",
      "          Go       0.98      0.88      0.93        50\n",
      "     Haskell       0.90      0.67      0.77        67\n",
      "        Java       1.00      0.92      0.96        49\n",
      "  JavaScript       0.85      0.72      0.78        54\n",
      "       Julia       0.90      0.56      0.69        32\n",
      "      Kotlin       0.97      0.97      0.97        32\n",
      "      MATLAB       0.56      0.37      0.44        27\n",
      " Mathematica       0.36      0.85      0.51        46\n",
      "         PHP       0.74      0.71      0.72        24\n",
      "        Perl       0.91      0.91      0.91        57\n",
      "      Python       0.78      0.86      0.82        72\n",
      "           R       0.68      0.70      0.69        30\n",
      "        Ruby       0.88      0.82      0.85        55\n",
      "        Rust       1.00      0.90      0.95        21\n",
      "       Scala       0.88      0.88      0.88        40\n",
      "       Swift       0.75      0.60      0.67        20\n",
      "\n",
      "    accuracy                           0.81       811\n",
      "   macro avg       0.84      0.79      0.80       811\n",
      "weighted avg       0.85      0.81      0.82       811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,gbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e976ee7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m(labels_test, gbc_pred, normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12.8\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(conf_matrix, \n\u001b[1;32m      5\u001b[0m             cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYlGn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             annot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m    \u001b[38;5;66;03m#         fmt = '.2f',\u001b[39;00m\n\u001b[1;32m      8\u001b[0m             xticklabels \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique(),\n\u001b[1;32m      9\u001b[0m             yticklabels \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(labels_test, gbc_pred, normalize = 'true')\n",
    "plt.figure(figsize=(12.8,6))\n",
    "\n",
    "sns.heatmap(conf_matrix, \n",
    "            cmap=\"YlGn\",\n",
    "            annot = True,\n",
    "   #         fmt = '.2f',\n",
    "            xticklabels = df['language'].unique(),\n",
    "            yticklabels = df['language'].unique())\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title('Confusion matrix, normalised')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10f8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "     'Model': 'Gradient Boosting',\n",
    "     'Training Set Accuracy': accuracy_score(labels_train, best_gbc.predict(features_train)),\n",
    "     'Test Set Accuracy': accuracy_score(labels_test, gbc_pred)\n",
    "}\n",
    "\n",
    "df_models_gbc = pd.DataFrame(d, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a93c6a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.895797</td>\n",
       "      <td>0.807645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Training Set Accuracy  Test Set Accuracy\n",
       "0  Gradient Boosting               0.895797           0.807645"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80569ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Models/best_gbc.pickle', 'wb') as output:\n",
    "    pickle.dump(best_gbc, output)\n",
    "    \n",
    "with open('Models/df_models_gbc.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_gbc, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
